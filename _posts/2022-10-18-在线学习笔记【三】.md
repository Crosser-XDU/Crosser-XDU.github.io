在上一篇文章中，我们介绍并分析了FTL算法，发现FTL算法在在线二次规划问题上能够获得还不错的效果，但是FTL算法的设计太简单，对于许多问题还无法得到好的结果，接下来，我们将给出一个例子，并分析FTL算法在这个例子上的表现，从而引出FTRL算法，并且从FTRL算法引出下面一篇将要分析的OGD算法。

## The Failure Of FTL

下面我们将给出一个有关在线线性优化的例子，并推出FTL在这个例子上的Regret Bound。

在这个例子中，解空间$S =[-1,1]\in R$并且$t$轮的损失函数满足

$f_t(w)=z_t w$,  $$z_t= \begin{cases}-0.5 & \text { if } t=1 \\ 1 & \text { if } t \text { is even } \\ -1 & \text { if } t>1 \wedge t \text { is odd }\end{cases}$$

那么，对于这样一个问题 ，其实我们可以看到，当运用FTL算法来预测就会出现当$t$为偶数时$\mathbf{w_t}$会被预测为1，而当$t$为奇数时$\mathbf{w_t}$就会被预测为-1，可以看到，$T$轮的累计损失为$T$，而$\min_{\mathbf{u} \in S} \sum_{t=1}^T f_t(\mathbf{u})$为0，所以该算法在这个问题上的Regret Bound就会到 T ，可以看到此时这个算法的效果就不好了，它在每一轮都和实际的结果不同。那为什么FTL算法在上面的例子中表现得效果就不好了呢？直观上分析，上面的例子中每一轮的损失函数变化的幅度太大了，而我们的FTL算法又只在每次预测时考虑最小化过去的损失和，这样就会太收过去的影响，从而过于拟合过去的数据，就像在传统学习中的过拟合问题一样。就像传统学习中利用正则化项解决过拟合问题一样，我们在FTL的算法中加入正则化项，也就有了Follow-The-Regularized-Leader (FTRL)算法。下面将介绍FTRL算法。

## FTRL

FTRL在FTL的基础上加入了正则化项$R(\mathbf{w})$。用数学具体表示就是：

$\forall t, \quad \mathbf{w_t}=\underset{\mathbf{w} \in S}{\operatorname{argmin}} \sum_{i=1}^{t-1} f_i(\mathbf{w})+R(\mathbf{w})$

根据加入正则化项的不同，也有了不同的具体算法。当我们对在线线性优化问题上（损失函数$f_t(\mathbf{w_t})=<w_t,z_t>$）用正则化项$R(\mathbf{w})=\frac{1}{2 \eta}\|\mathbf{w}\|2^2$，并且解空间$S$为$R^d$时，我们就可以得出：



